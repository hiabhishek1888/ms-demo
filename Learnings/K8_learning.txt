checking the change in k8s learning !!
 i am lost :{}

A little background, To understand it, 
I have a laptop and LIMA VM running on top of it and i am able to create k8 cluster successfully and deployed app on it,
I am also getting the APIs response internally, within the cluster network. 

Challenge 1: 
Now i have decided to get the response over my laptop, Outside cluster network. 
- NOTE: lima supports two type of Virtualizer, 1. vz(macOS virtualization) and 2. qemu (multi-os virtualizer)
Few solutions were: 
- port forwarding (vz virtualizer supports only port forwarding, complex setup for bridge n/w)
- bridge networking (qemu suports both)

Solution 1:
    For simplicity, i went with port forwarding.
    So, when i configured port forwarding for port 30080 (nodeport), it was not working even after multiple google and gpt tries.
    To test if its issue from Lima end, I ran a simple python/go server on same 30080 port, 
        on same master node VM where k8 nodeport is already exposed on same port,
        Guess what, 

Issue 1: 
    - when i just tested go server, it just responded to request from my laptop.
        When i shut the go server, i should get something from nodeport, NO, nothing !!
        So, now its like "there is some issue with my K8 app" but it was working fine internally.
    - Tried everything with my app. 
    - Again i tried to check if any packet am i recieving or not via tcpdump on that port with both go server and nodeport. captured go packets but not for nodeport.
        So one thing was clear that no request is reaching within VM for nodeport.

High level Cause for Issue 1: 
    - Netstat shows only the go server but not the nodeport, diging little deeper, i found that nodeport do not shows with netstat, 
    - why? see below "K8s NODEPORT UNUSUAL INTERNAL WORKING WITH PORT FORWARDING", then start from here;
    - In short, K8 internally modifies the kernel IPtables to get the request on 30080 and 
        and hence you do not see with netstat and neither my port forwarding was working on that.
        however my go server binds port in user space and thats why its visible in netstat and properly responding with port forwarding

    - Still the question was: 
    - Does port forwarding only works with what app runs/exposed within "user space" ports ???
        YES. 
    - Why ? Example is Go server app: Because, servers created/ app exposed with ports within user space 
            creates a process which respond to port forwarding from host machine,
            and also on host, VM will also create a process to listen and forward to guest.
            this didn't happened in nodeport.

Work Around for Issue 1: 
    - Ok, so we hadd 2 ways: 
        - hit the kernel ip directly, goes to user space. (localhost - user space)
        - Bridge Lima VM to your Mac’s real network 
    - Went with kernel ip because bridging is not possible with LIMA vm with vz virtualiser, for that you need QEMU(via socket_vmnet). 
    - guess what, to hit directly kernel space, we have to directly hit VM ip 
        (which was already failing but i didn't know why.. "i thought localhost and ip forwarding are same" )
    - So, yes, there is localhost and ip based port forwarding, one hits user space and other hit kernel iptable directly, respectively.
    
    Issue 2:
        - Now, LIMA VM LIMITATION: It only supports "user space tcp forwarding" not the kernel, so only localhost forwarding works
    Work Around for issue 2:
        - so next solution is to use reverse proxy (kind of): user-space reverse proxy
        - what it will do:
        - Mac (curl localhost:29999) 
        -   → Lima forwards to VM:29999 - (within user space)
        -     → Go app listens on 29999, running within cluser, forwards to localhost:30080 (NodePort) - (to kernal iptable)
        -       → iptables → K8s Service → Pod:8080


Root Cause for Issue 1: 
    - is it limitation of lima that it only supports "user-space port forwarding" ?
    - YES
Solution: 
    - use Virtual box - uses Kernel-level (via NAT engine).


Lesson Learnt: 
    Apart from microservices, docker and K8 fundamentals, i learnt:
    - Always use latest version of K8 
        (almost app components were stuck in crashloopbackoff..
        wasted almost 1 whole day to find the issue)
    - k8 storage class - PersistentVolumeClaims, 
        Database pods (the StatefulSets) will stuck in Pending because their PersistentVolumeClaims (PVCs) cannot be fulfilled
        — there is no default StorageClass or dynamic storage provisioner in kubeadm cluster by default.
        For local/multinode clusters, a solution is to install the local-path-provisioner, which uses local disk on each node for storage.
        for database you need to assign a storage class.

    - there is something called user-space & kernel ipvtable based port forwarding too..
    - netstat & lsof, tcp dump
    - localhost vs ip based forwarding
    - LIMA unusual behaviour (limitation) with port forwarding.
    - reverse proxy - coded with gpt.
    - Always go for tools which is more used and more community base.
    - FUCK LIMA FOR WASTING 2 WORKING DAYS



LIMA UNUSUAL INTERNAL WORKING WITH PORT FORWARDING (explored via K8s NODEPORT): 

- whenever we expose a normal server on a particular port, 
    - it always create & bind a process to that port, 
    - so that it continously listen traffic on that port.
    - and it is exposed witin "user-space".
    - to chech what services are listeninig on what port within "user-space" 
        - you can use `sudo netstat -tulnp | grep <port>`.
- but whenever we expose a server via Nodeport within K8s, 
    - it modifies Kernel IPTables (which is not in "user" space)
    - and do not create a process for it
    - instead, it directly intercepts traffic on port 30080 and 
    - directly forward/routes traffic to a pod 8080 (default) via cluster networks.
    - TECHNICALLY, 
        - Traffic reaches Node's port 30080
            - The packet hits any Kubernetes node (master or worker).
            - Port 30080 is open at kernel level, but no user-space process is listening.
        - kube-proxy intercepts using iptables (or IPVS)
            - Kube proxy configures the IPtable rules to catch traffic on port 30080
            - iptables rewrites the destination IP/port of that packet → forwards to a Pod IP on port 8080.
        - Packet is forwarded to a Pod
            - The worker node picks a healthy Pod from the endpoints list (based on the selector in the Service).
            - It balances traffic using iptables' random match or IPVS round-robin.
            - The traffic is then DNAT'ed (Destination NAT) and delivered.

        - Pod receives request on port 8080
            - The Pod’s container handles it.
            - The response is routed back to the requester (via SNAT).

    - to check where k8s nodeport is exposed (by default, port 30080) (modified kernel ip tables) 
        - you can use - `sudo iptables -t nat -L -n | grep <port>`

 



Few commands:

---
sudo snap install go  --classic

---
kubectl get svc --all-namespaces -o=jsonpath="{range .items[?(@.spec.type=='NodePort')]}{.metadata.name}{': '}{range .spec.ports[*]}{.port}{' => '}{.nodePort}{'\n'}{end}{end}"

---
#Netcat port check: is it open and listening?
nc -zv <ip> <port>	
---
#Old-school but still works for port connectivity check
telnet <ip> <port>	


---
# Get NodePort value of a service
kubectl get svc <svc-name> -o=jsonpath='{.spec.ports[0].nodePort}'
---
# Restart a deployment to test pod re-creation
kubectl rollout restart deployment <deployment-name>
---
# Simulate pod failure (graceful)
kubectl delete pod <pod-name>


---
# Get and Edit kube-proxy configmap (this defines iptables vs ipvs, mode, etc.)
kubectl -n kube-system edit configmap kube-proxy
# Restart kube-proxy pods (they’re in DaemonSet, so this restarts per node)
kubectl -n kube-system delete pod -l k8s-app=kube-proxy

---
# Get external IP of any node
kubectl get nodes -o jsonpath='{.items[*].status.addresses[?(@.type=="InternalIP")].address}'
---
# Get Internal IP of nodes (host IP to access NodePort)
kubectl get nodes -o jsonpath='{.items[*].status.addresses[?(@.type=="InternalIP")].address}'
---
# Get actual service endpoints resolved from selector
kubectl get endpoints <your-service-name>

---
#get the log of specific kube components
kubectl -n kube-system logs -l k8s-app=<component-name>
eg:     kubectl -n kube-system logs -l k8s-app=kube-proxy
---
#View kubelet logs
journalctl -u kubelet
---
kubectl logs <pod-name>



---
#Test host → guest connectivity
curl -v http://<VM-IP>:<NodePort>
nc -zv <VM-IP> <NodePort>

====

# Check certificate expiration (with detailed dates)
sudo kubeadm certs check-expiration -v=5

# Manually inspect certificate contents
sudo openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout | grep -A2 Validity

# Force-renew all certificates
sudo kubeadm certs renew all --config=/etc/kubernetes/kubeadm-config.yaml

# Verify certificate chain
openssl verify -CAfile /etc/kubernetes/pki/ca.crt /etc/kubernetes/pki/apiserver.crt

====